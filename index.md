---
layout: homepage
---

## About Me

I am an assistant professor, Ph.D. advisor at [the School of Artificial Intelligence](https://soai.sjtu.edu.cn), [Shanghai Jiao Tong University](https://www.sjtu.edu.cn). I obtained my Ph.D. at [the Department of Electronic and Computer Engineering](https://cde.nus.edu.sg/ece/), [National University of Singapore](https://nus.edu.sg/) in June 2025, supervised by [Prof. Xinchao Wang](https://sites.google.com/site/sitexinchaowang/). Before that, I received my bachelor's degree in [the Department of Computer Science and Technology](https://cs.nju.edu.cn/) from [Nanjing University](https://www.nju.edu.cn/) in 2021. I was also fortunate to work as a research intern at [Rutgers University](http://www.rutgers.edu/) under the supervision of [Prof. Hao Wang](http://www.wanghao.in/) and at [Baidu Inc.](http://research.baidu.com/) under the supervision of [Tianwei Lin](https://wzmsltw.github.io/).

My research interests include <b><i style="color:#7b5aa6">generative AI, especially efficient deep learning driven by synthetic data.</i></b>. Currently, I am creating <b><i style="color:#7b5aa6">Go-There Lab</i></b> and recruiting **Postdocs (1 position available currently)**, **Ph.D. students (2~3 every year starting from fall 2027), Master students (1~2 every year starting from fall 2027), and multiple research interns**. <span style="color: red;">If you are interested in working with me at Shanghai Jiao Tong University on the following topics:</span>

1. <b><i style="color:#7b5aa6">Generative AI: Principle and Architecture</i></b>;
2. <b><i style="color:#7b5aa6">Broad Topics and Applications in AIGC</i></b>;
3. <b><i style="color:#7b5aa6">Deep Learning driven by Synthetic Data</i></b>;

<span style="color: red;">feel free to reach out via</span> liusonghua{AT}sjtu.edu.cn<span style="color: red;">. We are always looking for self-motivated students actively.</span>

<span style="color: red;">Currently, I have run out of Ph.D. positions for 2026.</span>

## News

> Last Update: 2025.12.15

[2025.12] ðŸ”¥We release [EditMGT](https://arxiv.org/abs/2512.11715), an instructional image editor based on Masked Generative Transformer (MGT). It adaptively localizes editing region during generation and achieves competitive results to state-of-the-art diffusion models with less than 1B parameters. [[Page]](https://weichow23.github.io/EditMGT/) [[Codes]](https://github.com/weichow23/EditMGT) [[Dataset]](https://huggingface.co/datasets/WeiChow/CrispEdit-2M)

[2025.11] ðŸ”¥We release [ViBT](https://arxiv.org/abs/2511.23199). It's the first time that bridge models are scaled to 20B models, which brings new opportunities for vision-to-vision translation tasks, e.g., image/video editing, controllable image/video generation, etc. [[Page]](https://yuanshi9815.github.io/ViBT_homepage) [[Codes]](https://github.com/Yuanshi9815/ViBT) [[Demo]](https://huggingface.co/spaces/Yuanshi/ViBT)

[2025.11] ðŸ”¥We release [FreeSwim](https://arxiv.org/abs/2511.14712), a training-free method that generates 4K-scale videos! Codes are available [here](https://github.com/WillWu111/FreeSwim).

[2025.11] ðŸ”¥FreLay, a stronger extension of [WinWinLay](https://arxiv.org/abs/2506.15563), is accepted by AAAI 2026!ðŸŽ‰

[2025.09] ðŸ”¥2 papers are accepted by NeurIPS 2025! Congratulations to Ms. Yujia Hu for having her first research work accepted!ðŸŽ‰

[2025.06] ðŸ”¥We release [WinWinLay](https://arxiv.org/abs/2506.15563), a training-free layout-to-image method that advances both worlds of precision and realism.

[2025.06] ðŸ”¥3 papers are accepted by ICCV 2025, including one oral presentation! Congratulations to Ms. Ruonan Yu and all co-authors!ðŸŽ‰

[2025.05] ðŸ”¥We release [IEAP](https://arxiv.org/abs/2506.04158): ~~Your Free GPT-4o Image Editor~~. It decouples a complex image editing instruction into several programmable atomic operations and achieves compelling performance! Codes are available [here](https://github.com/YujiaHu1109/IEAP)!ðŸš€ Demo is available [here](https://huggingface.co/spaces/Cicici1109/IEAP).ðŸ¤— 

[2025.05] ðŸ”¥We release [LLaVA-Meteor](https://arxiv.org/abs/2505.11945), a novel, efficient, and promising method to process visual tokens in VLM.

[2025.05] Congratulations to Mr. Xinhao Tan for having his work accepted at ACL 2025 during his undergraduate period!ðŸŽ‰

[2025.05] ðŸ”¥2 papers are accepted by ICML 2025! Congratulations to all co-authors!ðŸŽ‰

[2025.04] ðŸ”¥We release [Flash Sculptor](https://arxiv.org/abs/2504.06178), an efficient and scalable solution to reconstruct a complex and compositional 3D scene from merely a single image! Try it [here](https://github.com/YujiaHu1109/Flash-Sculptor)ðŸš€

[2025.03] ðŸ”¥We release [URAE](https://arxiv.org/abs/2503.16322): ~~Your Free FLUX Pro Ultra~~. It adapts pre-trained diffusion transformers like FLUX to 4K resolution with merely 3K training samples! Codes are available [here](https://github.com/Huage001/URAE)!ðŸš€ Demos are available [here](https://huggingface.co/spaces/Yuanshi/URAE) and [here](https://huggingface.co/spaces/Yuanshi/URAE_dev).ðŸ¤— 

[2025.03] ðŸ”¥We release [OminiControl2](https://arxiv.org/abs/2503.08280)! OminiControl1 has achieved impressive results on controllable generation. Now, OminiControl2 makes it efficient as well!

[2025.03] ðŸ”¥We release [CFM](https://www.arxiv.org/abs/2503.01212)! Spectral Filtering provides dataset distillation with a unified perspective!

[2025.02] ðŸ”¥3 papers are accepted by CVPR 2025! Congratulations to all co-authors!ðŸŽ‰

[2025.02] ðŸ”¥We release a benchmark for large-scale dataset compression [here](https://arxiv.org/abs/2502.06434). Try it [here](https://github.com/ArmandXiao/Rethinking-Dataset-Compression)!ðŸš€

[2024.12] ðŸ”¥We release [CLEAR](https://arxiv.org/abs/2412.16112), a simple-yet-effective strategy to linearize the complexity of pre-trained diffusion transformers, such as FLUX and SD3. Try it [here](https://github.com/Huage001/CLEAR)!ðŸš€

[2024.12] ðŸ”¥We release [OminiControl](https://arxiv.org/abs/2411.15098), a minimal yet powerful universal control framework for Diffusion Transformer models like FLUX. Try it [here](https://github.com/Yuanshi9815/OminiControl)!ðŸš€

{% include_relative _includes/publications.md %}
