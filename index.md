---
layout: homepage
---

## About Me

I am an assistant professor, Ph.D. advisor at [the School of Artificial Intelligence](https://soai.sjtu.edu.cn), [Shanghai Jiao Tong University](https://www.sjtu.edu.cn). I obtained my Ph.D. at [the Department of Electronic and Computer Engineering](https://cde.nus.edu.sg/ece/), [National University of Singapore](https://nus.edu.sg/) in June 2025, supervised by [Prof. Xinchao Wang](https://sites.google.com/site/sitexinchaowang/). Before that, I received my bachelor's degree in [the Department of Computer Science and Technology](https://cs.nju.edu.cn/) from [Nanjing University](https://www.nju.edu.cn/) in 2021. I was also fortunate to work as a research intern at [Rutgers University](http://www.rutgers.edu/) under the supervision of [Prof. Hao Wang](http://www.wanghao.in/) and at [Baidu Inc.](http://research.baidu.com/) under the supervision of [Tianwei Lin](https://wzmsltw.github.io/).

My research interests include <b><i style="color:#7b5aa6">visual synthesis and training with synthetic data</i></b>. Since 2020, I have published over 10 first-author research papers at top journals/conferences on these topics. Multiple works are selected as paper award nominations, oral, highlight, and spotlight. During my doctoral studies, I received the NUS Research Scholarship and the 2023 National Award for Outstanding Self-financed Chinese Students Abroad.

Currently, I am creating <b><i style="color:#7b5aa6">Learning and Synthesis Hub</i></b> and recruiting **Ph.D. students (2~3 every year starting from fall 2026), Master students (1~2 every year starting from fall 2026), and multiple research interns**. <span style="color: red;">If you are interested in working with me at Shanghai Jiao Tong University on the following topics:</span>

1. <b><i style="color:#7b5aa6">Model Editing for Novel Functionalities, Efficiency, Generalizability, and Safety</i></b>;
2. <b><i style="color:#7b5aa6">Training with Synthetic Data</i></b>;
3. <b><i style="color:#7b5aa6">Visual Generative Model</i></b>;
4. <b><i style="color:#7b5aa6">Applications of the above topics to broader domains</i></b>, *e.g.*, art, science, robotics, multimedia, *etc.*,

<span style="color: red;">feel free to reach out via</span> liusonghua{AT}sjtu.edu.cn / liusonghua_site{AT}163.com<span style="color: red;">. We are always looking for self-motivated students actively.</span>

<span style="color: red;">Currently, I have run out of Ph.D. positions for 2026. There is 1 Master position for 2026 left.</span>

## News

> Last Update: 2025.07.01

[2025.06] ðŸ”¥We release [WinWinLay](https://arxiv.org/abs/2506.15563), a training-free layout-to-image method that advances both worlds of precision and realism.

[2025.06] ðŸ”¥3 papers are accepted by ICCV 2025! Congratulations to all co-authors!ðŸŽ‰

[2025.05] ðŸ”¥We release [IEAP](https://arxiv.org/abs/2506.04158): ~~Your Free GPT-4o Image Editor~~. It decouples a complex image editing instruction into several programmable atomic operations and achieves compelling performance! Codes are available [here](https://github.com/YujiaHu1109/IEAP)!ðŸš€ Demo is available [here](https://huggingface.co/spaces/Cicici1109/IEAP).ðŸ¤— 

[2025.05] ðŸ”¥We release [LLaVA-Meteor](https://arxiv.org/abs/2505.11945), a novel, efficient, and promising method to process visual tokens in VLM.

[2025.05] Congratulations to Mr. Xinhao Tan for having his work accepted at ACL 2025 during his undergraduate period!ðŸŽ‰

[2025.05] ðŸ”¥2 papers are accepted by ICML 2025! Congratulations to all co-authors!ðŸŽ‰

[2025.04] ðŸ”¥We release [Flash Sculptor](https://arxiv.org/abs/2504.06178), an efficient and scalable solution to reconstruct a complex and compositional 3D scene from merely a single image! Try it [here](https://github.com/YujiaHu1109/Flash-Sculptor)ðŸš€

[2025.03] ðŸ”¥We release [URAE](https://arxiv.org/abs/2503.16322): ~~Your Free FLUX Pro Ultra~~. It adapts pre-trained diffusion transformers like FLUX to 4K resolution with merely 3K training samples! Codes are available [here](https://github.com/Huage001/URAE)!ðŸš€ Demos are available [here](https://huggingface.co/spaces/Yuanshi/URAE) and [here](https://huggingface.co/spaces/Yuanshi/URAE_dev).ðŸ¤— 

[2025.03] ðŸ”¥We release [OminiControl2](https://arxiv.org/abs/2503.08280)! OminiControl1 has achieved impressive results on controllable generation. Now, OminiControl2 makes it efficient as well!

[2025.03] ðŸ”¥We release [CFM](https://www.arxiv.org/abs/2503.01212)! Spectral Filtering provides dataset distillation with a unified perspective!

[2025.02] ðŸ”¥3 papers are accepted by CVPR 2025! Congratulations to all co-authors!ðŸŽ‰

[2025.02] ðŸ”¥We release a benchmark for large-scale dataset compression [here](https://arxiv.org/abs/2502.06434). Try it [here](https://github.com/ArmandXiao/Rethinking-Dataset-Compression)!ðŸš€

[2024.12] ðŸ”¥We release [CLEAR](https://arxiv.org/abs/2412.16112), a simple-yet-effective strategy to linearize the complexity of pre-trained diffusion transformers, such as FLUX and SD3. Try it [here](https://github.com/Huage001/CLEAR)!ðŸš€

[2024.12] ðŸ”¥We release [OminiControl](https://arxiv.org/abs/2411.15098), a minimal yet powerful universal control framework for Diffusion Transformer models like FLUX. Try it [here](https://github.com/Yuanshi9815/OminiControl)!ðŸš€

{% include_relative _includes/publications.md %}
